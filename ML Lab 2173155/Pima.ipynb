{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pima.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3zTN_SVuXqW",
        "colab_type": "text"
      },
      "source": [
        "**Assignment Lab 1**\n",
        "\n",
        "Neural Networks Using Pima Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab_MxUTUuDXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1e13a442-8ae7-4e48-c896-2f0bc5a6952d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use(\"fivethirtyeight\")\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTNMkOo8uzBN",
        "colab_type": "text"
      },
      "source": [
        "Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClH18za5u2hR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "71a819b0-7c8e-4daa-8b86-54c46aade7be"
      },
      "source": [
        "dataset = pd.read_csv('/content/pima-indians-diabetes.csv')\n",
        "dataset.head()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>148</th>\n",
              "      <th>72</th>\n",
              "      <th>35</th>\n",
              "      <th>0</th>\n",
              "      <th>33.6</th>\n",
              "      <th>0.627</th>\n",
              "      <th>50</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   6  148  72  35    0  33.6  0.627  50  1\n",
              "0  1   85  66  29    0  26.6  0.351  31  0\n",
              "1  8  183  64   0    0  23.3  0.672  32  1\n",
              "2  1   89  66  23   94  28.1  0.167  21  0\n",
              "3  0  137  40  35  168  43.1  2.288  33  1\n",
              "4  5  116  74   0    0  25.6  0.201  30  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUzwVYVIvFBt",
        "colab_type": "text"
      },
      "source": [
        "Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxs__wM-vGpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "5153efb5-fb0c-4316-d75c-702aa6eab098"
      },
      "source": [
        "dataset.describe().transpose()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>767.0</td>\n",
              "      <td>3.842243</td>\n",
              "      <td>3.370877</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>17.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>767.0</td>\n",
              "      <td>120.859192</td>\n",
              "      <td>31.978468</td>\n",
              "      <td>0.000</td>\n",
              "      <td>99.0000</td>\n",
              "      <td>117.000</td>\n",
              "      <td>140.000</td>\n",
              "      <td>199.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>767.0</td>\n",
              "      <td>69.101695</td>\n",
              "      <td>19.368155</td>\n",
              "      <td>0.000</td>\n",
              "      <td>62.0000</td>\n",
              "      <td>72.000</td>\n",
              "      <td>80.000</td>\n",
              "      <td>122.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>767.0</td>\n",
              "      <td>20.517601</td>\n",
              "      <td>15.954059</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>99.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767.0</td>\n",
              "      <td>79.903520</td>\n",
              "      <td>115.283105</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>127.500</td>\n",
              "      <td>846.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33.6</th>\n",
              "      <td>767.0</td>\n",
              "      <td>31.990482</td>\n",
              "      <td>7.889091</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.3000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>36.600</td>\n",
              "      <td>67.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.627</th>\n",
              "      <td>767.0</td>\n",
              "      <td>0.471674</td>\n",
              "      <td>0.331497</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.2435</td>\n",
              "      <td>0.371</td>\n",
              "      <td>0.625</td>\n",
              "      <td>2.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>767.0</td>\n",
              "      <td>33.219035</td>\n",
              "      <td>11.752296</td>\n",
              "      <td>21.000</td>\n",
              "      <td>24.0000</td>\n",
              "      <td>29.000</td>\n",
              "      <td>41.000</td>\n",
              "      <td>81.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>767.0</td>\n",
              "      <td>0.348110</td>\n",
              "      <td>0.476682</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       count        mean         std     min      25%      50%      75%     max\n",
              "6      767.0    3.842243    3.370877   0.000   1.0000    3.000    6.000   17.00\n",
              "148    767.0  120.859192   31.978468   0.000  99.0000  117.000  140.000  199.00\n",
              "72     767.0   69.101695   19.368155   0.000  62.0000   72.000   80.000  122.00\n",
              "35     767.0   20.517601   15.954059   0.000   0.0000   23.000   32.000   99.00\n",
              "0      767.0   79.903520  115.283105   0.000   0.0000   32.000  127.500  846.00\n",
              "33.6   767.0   31.990482    7.889091   0.000  27.3000   32.000   36.600   67.10\n",
              "0.627  767.0    0.471674    0.331497   0.078   0.2435    0.371    0.625    2.42\n",
              "50     767.0   33.219035   11.752296  21.000  24.0000   29.000   41.000   81.00\n",
              "1      767.0    0.348110    0.476682   0.000   0.0000    0.000    1.000    1.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxEKZPJYvMCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "99f9b7ee-daf6-40b7-f9e7-789cd6aadab8"
      },
      "source": [
        "sns.heatmap(dataset.corr())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9617098278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMAg1TyGvN8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "e9d4d9b9-76ce-4528-f99e-00be9876f4b0"
      },
      "source": [
        "dataset.corr()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>148</th>\n",
              "      <th>72</th>\n",
              "      <th>35</th>\n",
              "      <th>0</th>\n",
              "      <th>33.6</th>\n",
              "      <th>0.627</th>\n",
              "      <th>50</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.128846</td>\n",
              "      <td>0.141197</td>\n",
              "      <td>-0.082495</td>\n",
              "      <td>-0.072999</td>\n",
              "      <td>0.017518</td>\n",
              "      <td>-0.033927</td>\n",
              "      <td>0.544018</td>\n",
              "      <td>0.221087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.128846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.152498</td>\n",
              "      <td>0.056381</td>\n",
              "      <td>0.332383</td>\n",
              "      <td>0.220955</td>\n",
              "      <td>0.136903</td>\n",
              "      <td>0.262408</td>\n",
              "      <td>0.465856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.141197</td>\n",
              "      <td>0.152498</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207308</td>\n",
              "      <td>0.089098</td>\n",
              "      <td>0.281777</td>\n",
              "      <td>0.041180</td>\n",
              "      <td>0.239571</td>\n",
              "      <td>0.064882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.082495</td>\n",
              "      <td>0.056381</td>\n",
              "      <td>0.207308</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.437974</td>\n",
              "      <td>0.392553</td>\n",
              "      <td>0.183498</td>\n",
              "      <td>-0.115873</td>\n",
              "      <td>0.073265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.072999</td>\n",
              "      <td>0.332383</td>\n",
              "      <td>0.089098</td>\n",
              "      <td>0.437974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.198111</td>\n",
              "      <td>0.185579</td>\n",
              "      <td>-0.040942</td>\n",
              "      <td>0.131984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33.6</th>\n",
              "      <td>0.017518</td>\n",
              "      <td>0.220955</td>\n",
              "      <td>0.281777</td>\n",
              "      <td>0.392553</td>\n",
              "      <td>0.198111</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140546</td>\n",
              "      <td>0.035911</td>\n",
              "      <td>0.292695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.627</th>\n",
              "      <td>-0.033927</td>\n",
              "      <td>0.136903</td>\n",
              "      <td>0.041180</td>\n",
              "      <td>0.183498</td>\n",
              "      <td>0.185579</td>\n",
              "      <td>0.140546</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032738</td>\n",
              "      <td>0.173245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.544018</td>\n",
              "      <td>0.262408</td>\n",
              "      <td>0.239571</td>\n",
              "      <td>-0.115873</td>\n",
              "      <td>-0.040942</td>\n",
              "      <td>0.035911</td>\n",
              "      <td>0.032738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.236417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.221087</td>\n",
              "      <td>0.465856</td>\n",
              "      <td>0.064882</td>\n",
              "      <td>0.073265</td>\n",
              "      <td>0.131984</td>\n",
              "      <td>0.292695</td>\n",
              "      <td>0.173245</td>\n",
              "      <td>0.236417</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              6       148        72  ...     0.627        50         1\n",
              "6      1.000000  0.128846  0.141197  ... -0.033927  0.544018  0.221087\n",
              "148    0.128846  1.000000  0.152498  ...  0.136903  0.262408  0.465856\n",
              "72     0.141197  0.152498  1.000000  ...  0.041180  0.239571  0.064882\n",
              "35    -0.082495  0.056381  0.207308  ...  0.183498 -0.115873  0.073265\n",
              "0     -0.072999  0.332383  0.089098  ...  0.185579 -0.040942  0.131984\n",
              "33.6   0.017518  0.220955  0.281777  ...  0.140546  0.035911  0.292695\n",
              "0.627 -0.033927  0.136903  0.041180  ...  1.000000  0.032738  0.173245\n",
              "50     0.544018  0.262408  0.239571  ...  0.032738  1.000000  0.236417\n",
              "1      0.221087  0.465856  0.064882  ...  0.173245  0.236417  1.000000\n",
              "\n",
              "[9 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy840iSPvRi8",
        "colab_type": "text"
      },
      "source": [
        "Training and Testing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b0HI2mQvVHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separating the data\n",
        "x_data=dataset.iloc[:,0:8].values\n",
        "y_data=dataset.iloc[:,8:].values\n",
        "#splitting the data into training and testing\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,random_state=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joTdFMxVvamW",
        "colab_type": "text"
      },
      "source": [
        "Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHUh7_O1vcao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_creation(opt='adam',init='uniform'):\n",
        "    model=Sequential()\n",
        "    model.add(Dense(12,input_dim=8,kernel_initializer=init,activation='relu'))\n",
        "    model.add(Dense(8,kernel_initializer=init,activation='relu'))\n",
        "    model.add(Dense(8,kernel_initializer=init,activation='relu'))\n",
        "    model.add(Dense(1,kernel_initializer=init,activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model=model_creation()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYzrDz6avmZF",
        "colab_type": "text"
      },
      "source": [
        "Traing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKPJSnABvkra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d96fe8c-92f7-4ff2-f936-7825aa4a942c"
      },
      "source": [
        "values=model.fit(x_train,y_train,epochs=100,batch_size=10,verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8330\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8191\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 0s 996us/step - loss: 0.3777 - accuracy: 0.8313\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 0s 963us/step - loss: 0.3839 - accuracy: 0.8313\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 0s 968us/step - loss: 0.3716 - accuracy: 0.8296\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 0s 965us/step - loss: 0.3736 - accuracy: 0.8278\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 0s 895us/step - loss: 0.3706 - accuracy: 0.8435\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 0s 973us/step - loss: 0.3742 - accuracy: 0.8278\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8313\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 0s 937us/step - loss: 0.3825 - accuracy: 0.8296\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8365\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 0s 960us/step - loss: 0.3715 - accuracy: 0.8278\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 0s 984us/step - loss: 0.3838 - accuracy: 0.8261\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 0s 923us/step - loss: 0.3666 - accuracy: 0.8383\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 0s 931us/step - loss: 0.3731 - accuracy: 0.8365\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8365\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8313\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8191\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8313\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 0s 979us/step - loss: 0.3693 - accuracy: 0.8365\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 0s 956us/step - loss: 0.3783 - accuracy: 0.8296\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 0s 966us/step - loss: 0.3623 - accuracy: 0.8504\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 0s 985us/step - loss: 0.3620 - accuracy: 0.8452\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 0s 908us/step - loss: 0.3665 - accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8330\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8365\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 0s 981us/step - loss: 0.3663 - accuracy: 0.8365\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 0s 989us/step - loss: 0.3766 - accuracy: 0.8296\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 0s 978us/step - loss: 0.3603 - accuracy: 0.8417\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 0s 935us/step - loss: 0.3552 - accuracy: 0.8383\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 0s 933us/step - loss: 0.3745 - accuracy: 0.8313\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 0s 947us/step - loss: 0.3932 - accuracy: 0.8157\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 0s 928us/step - loss: 0.3890 - accuracy: 0.8313\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 0s 970us/step - loss: 0.3705 - accuracy: 0.8261\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8330\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 0s 993us/step - loss: 0.3697 - accuracy: 0.8348\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8400\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8383\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8417\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 0s 951us/step - loss: 0.3700 - accuracy: 0.8296\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 0s 920us/step - loss: 0.3649 - accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 0s 897us/step - loss: 0.3676 - accuracy: 0.8365\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 0s 998us/step - loss: 0.3669 - accuracy: 0.8365\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 0s 992us/step - loss: 0.3743 - accuracy: 0.8383\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 0s 920us/step - loss: 0.3534 - accuracy: 0.8383\n",
            "Epoch 46/100\n",
            "58/58 [==============================] - 0s 991us/step - loss: 0.3587 - accuracy: 0.8435\n",
            "Epoch 47/100\n",
            "58/58 [==============================] - 0s 947us/step - loss: 0.3740 - accuracy: 0.8278\n",
            "Epoch 48/100\n",
            "58/58 [==============================] - 0s 986us/step - loss: 0.3581 - accuracy: 0.8383\n",
            "Epoch 49/100\n",
            "58/58 [==============================] - 0s 968us/step - loss: 0.3603 - accuracy: 0.8504\n",
            "Epoch 50/100\n",
            "58/58 [==============================] - 0s 974us/step - loss: 0.3751 - accuracy: 0.8383\n",
            "Epoch 51/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8383\n",
            "Epoch 52/100\n",
            "58/58 [==============================] - 0s 973us/step - loss: 0.3559 - accuracy: 0.8452\n",
            "Epoch 53/100\n",
            "58/58 [==============================] - 0s 976us/step - loss: 0.3603 - accuracy: 0.8348\n",
            "Epoch 54/100\n",
            "58/58 [==============================] - 0s 978us/step - loss: 0.3630 - accuracy: 0.8417\n",
            "Epoch 55/100\n",
            "58/58 [==============================] - 0s 951us/step - loss: 0.3566 - accuracy: 0.8417\n",
            "Epoch 56/100\n",
            "58/58 [==============================] - 0s 953us/step - loss: 0.3608 - accuracy: 0.8383\n",
            "Epoch 57/100\n",
            "58/58 [==============================] - 0s 989us/step - loss: 0.3638 - accuracy: 0.8383\n",
            "Epoch 58/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8487\n",
            "Epoch 59/100\n",
            "58/58 [==============================] - 0s 985us/step - loss: 0.3653 - accuracy: 0.8522\n",
            "Epoch 60/100\n",
            "58/58 [==============================] - 0s 962us/step - loss: 0.3545 - accuracy: 0.8504\n",
            "Epoch 61/100\n",
            "58/58 [==============================] - 0s 967us/step - loss: 0.3577 - accuracy: 0.8452\n",
            "Epoch 62/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8383\n",
            "Epoch 63/100\n",
            "58/58 [==============================] - 0s 977us/step - loss: 0.3641 - accuracy: 0.8539\n",
            "Epoch 64/100\n",
            "58/58 [==============================] - 0s 964us/step - loss: 0.3775 - accuracy: 0.8330\n",
            "Epoch 65/100\n",
            "58/58 [==============================] - 0s 918us/step - loss: 0.3658 - accuracy: 0.8487\n",
            "Epoch 66/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8452\n",
            "Epoch 67/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8452\n",
            "Epoch 68/100\n",
            "58/58 [==============================] - 0s 962us/step - loss: 0.3555 - accuracy: 0.8383\n",
            "Epoch 69/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8435\n",
            "Epoch 70/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8330\n",
            "Epoch 71/100\n",
            "58/58 [==============================] - 0s 927us/step - loss: 0.3668 - accuracy: 0.8330\n",
            "Epoch 72/100\n",
            "58/58 [==============================] - 0s 984us/step - loss: 0.3516 - accuracy: 0.8522\n",
            "Epoch 73/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8261\n",
            "Epoch 74/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8435\n",
            "Epoch 75/100\n",
            "58/58 [==============================] - 0s 993us/step - loss: 0.3586 - accuracy: 0.8296\n",
            "Epoch 76/100\n",
            "58/58 [==============================] - 0s 965us/step - loss: 0.3590 - accuracy: 0.8470\n",
            "Epoch 77/100\n",
            "58/58 [==============================] - 0s 995us/step - loss: 0.3567 - accuracy: 0.8209\n",
            "Epoch 78/100\n",
            "58/58 [==============================] - 0s 911us/step - loss: 0.3671 - accuracy: 0.8278\n",
            "Epoch 79/100\n",
            "58/58 [==============================] - 0s 905us/step - loss: 0.3582 - accuracy: 0.8574\n",
            "Epoch 80/100\n",
            "58/58 [==============================] - 0s 943us/step - loss: 0.3667 - accuracy: 0.8504\n",
            "Epoch 81/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8383\n",
            "Epoch 82/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8313\n",
            "Epoch 83/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8400\n",
            "Epoch 84/100\n",
            "58/58 [==============================] - 0s 982us/step - loss: 0.3557 - accuracy: 0.8383\n",
            "Epoch 85/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8504\n",
            "Epoch 86/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8487\n",
            "Epoch 88/100\n",
            "58/58 [==============================] - 0s 974us/step - loss: 0.3721 - accuracy: 0.8417\n",
            "Epoch 89/100\n",
            "58/58 [==============================] - 0s 957us/step - loss: 0.3454 - accuracy: 0.8487\n",
            "Epoch 90/100\n",
            "58/58 [==============================] - 0s 967us/step - loss: 0.3561 - accuracy: 0.8487\n",
            "Epoch 91/100\n",
            "58/58 [==============================] - 0s 975us/step - loss: 0.3639 - accuracy: 0.8383\n",
            "Epoch 92/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8452\n",
            "Epoch 93/100\n",
            "58/58 [==============================] - 0s 955us/step - loss: 0.3524 - accuracy: 0.8452\n",
            "Epoch 94/100\n",
            "58/58 [==============================] - 0s 983us/step - loss: 0.3501 - accuracy: 0.8522\n",
            "Epoch 95/100\n",
            "58/58 [==============================] - 0s 938us/step - loss: 0.3495 - accuracy: 0.8557\n",
            "Epoch 96/100\n",
            "58/58 [==============================] - 0s 943us/step - loss: 0.3469 - accuracy: 0.8487\n",
            "Epoch 97/100\n",
            "58/58 [==============================] - 0s 957us/step - loss: 0.3650 - accuracy: 0.8417\n",
            "Epoch 98/100\n",
            "58/58 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8400\n",
            "Epoch 99/100\n",
            "58/58 [==============================] - 0s 929us/step - loss: 0.3529 - accuracy: 0.8522\n",
            "Epoch 100/100\n",
            "58/58 [==============================] - 0s 964us/step - loss: 0.3649 - accuracy: 0.8348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxcIhOoFv6Jv",
        "colab_type": "text"
      },
      "source": [
        "Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9YGUh_Iv1_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f104e815-788a-4682-b4d3-31ca4a57c714"
      },
      "source": [
        "scores=model.evaluate(x_data,y_data)\n",
        "print(model.metrics_names[1],scores[1]*100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 905us/step - loss: 0.4210 - accuracy: 0.8096\n",
            "accuracy 80.96479773521423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-oexPyZv-yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict=model.predict(x_test,batch_size=10)\n",
        "y_predicted_labes=[]\n",
        "\n",
        "#changing outputs in the last layer in network\n",
        "for i in range(len(y_predict)):\n",
        "    if y_predict[i]>=0.5:\n",
        "        y_predicted_labes.append(1)\n",
        "    else:\n",
        "        y_predicted_labes.append(0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGGvlgMPwGHZ",
        "colab_type": "text"
      },
      "source": [
        "Analysing the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg3hPfYawJaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "d2b3cb03-55f4-4034-9290-895ab9e79b88"
      },
      "source": [
        "print(confusion_matrix(y_test,y_predicted_labes))\n",
        "print(classification_report(y_test,y_predicted_labes))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103  25]\n",
            " [ 32  32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.80      0.78       128\n",
            "           1       0.56      0.50      0.53        64\n",
            "\n",
            "    accuracy                           0.70       192\n",
            "   macro avg       0.66      0.65      0.66       192\n",
            "weighted avg       0.70      0.70      0.70       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}